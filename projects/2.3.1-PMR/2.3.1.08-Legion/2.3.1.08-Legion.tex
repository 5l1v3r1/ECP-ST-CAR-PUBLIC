\subsubsection{\stid{1.08} Legion}

\paragraph{Overview}
This project focuses on the development, hardening and support of the
Legion Programming System. Our focus is on the key capabilities (e.g.
correctness, performance, scalability) of an alternative, task-based
programming model for ECP that seeks to improve the amount of
available parallelism in applications.  In addition, it also enables a
separation of concerns of the implementation of an application from
how it is mapped onto a given system architecture.  Our efforts are
currently focused on addressing bugs, refactoring the implementation
for improved design and reduce complexity, hardening the source (via
testing and regression practices) and improving the scalability and
performance of entire system on current architectures that provide us
a path towards the future exascale systems.

The Legion programming system is freely available with an Apache-based
open source license and is hosted at GitLab:

\begin{quote} 
  \url{https://gitlab.com/StanfordLegion/legion}
\end{quote}

\paragraph{Key Challenges}
While Legion addresses a number of key challenges in improving system
utilization and some aspects of platform portability, it is a
relatively new programming system and therefore there is a cost to
rewriting applications.  This aspect makes significant adoption a risk
within ECP and additional effort must also take place to catch up with
aspects of performance and scaling to match aspects of more mature
technologies.

\paragraph{Solution Strategy}
As a collaboration between Los Alamos, Stanford University and other
efforts at NVIDIA and SLAC, we are providing the overarching
implementation Legion programming model that captures the ``best''
(correct and feature complete) version of the code.  In addition, we
are actively looking for opportunities to educate the ECP community
about Legion and other data-centric and task-based approaches to
programming.  We have been closely working with Combustion-Pele (AD
2.2.2.02) and the data analytics efforts in support of ExaFEL (AD
2.2.4.05) to provide support for Legion.  We also collaborate with the
LANL ATDM Programming Models and Runtimes project (ST 2.3.1.02), to
identify needs and requirements from the programming model and runtime
implementation.  This also includes management of the current
repository and quarterly releases of Legion to the broader community.
We also look at numerous aspects of having the Legion system
interoperate with today's more widely used programming systems --
e.g. MPI and OpenMP and more recently have started to look at
leveraging recent results in improving the performance of training
deep learning applications.  Results of using Legion in this context are
highlighted in~\cite{2.3.1.08:Jia:2018} and show a $3$-times improvement
in training throughput as well as the potential to significantly reduce
communication costs.  

Finally, we are actively exploring techniques to simplify Legion
programming that help in reducing the cost of adoption but also in
helping to educate the broader community about developing and
guaranteeing correctness and improving performance of Legion and
related programming systems~\cite{2.3.1.08:Lee:2018,
2.3.1.08:Lee:Correctness:2018}.

\paragraph{Recent Progress}
As discussed above, our progress to date has been focused on bug
fixes, performance improvements, and improvements in the programming
interface for the system.  In addition, we have started to diversify
and modularize the low-level transport layers of the system to use
both GASNetEX (ST 2.3.1.14) and a modern MPI layer. Additional work
has gone into addressing issues and performance concerns with running
at scale.  Although work is still continuing, we have seen numerous
improvements in performance and scaling that show promise in
alleviating the currently identified bottlenecks.

\paragraph{Next Steps}
Our plans for the next year are to continue focusing on the challenges
of the upcoming exasacle system architectures and on hardening and
improving the overall performance and scalability of the system.  We
have already starting running on Serria at Lawerence Livermore
National Laboratory and will continue until the system is no longer
avaialble for open testing and evaluation.  To date we have studies
and are working on improvements for $2,048$ nodes of Sierra. In
addition to user adoption and correcntess we feel these are key
components to long-term adoption and also for providing a viable
alternative programming system for ECP -- this includes initally
unforeseen use cases such as deep learning that are recent additions
to the Project's portfolio.  We will continue to seek out and improve
our educational outreach and developer productivity, including regular
(quarterly) open source releases of Legion and direct interactions
with the applications community as the also work with application
teams for debugging, fine-tuning of features for particular use cases
and overall performance tuning.
