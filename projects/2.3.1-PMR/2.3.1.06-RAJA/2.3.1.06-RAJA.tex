\subsubsection{ISC4MCM (RAJA)} 

\paragraph{Overview.} 
The Integrated Software Components for Managing Computation and Memory 
Interplay at Exascale (ISC4MCM) project is providing software libraries that 
enable application and library developers to meet advanced architecture 
portability challenges. The project goals are to enable writing performance 
portable computational kernels and coordinate complex heterogeneous memory 
resources among components in a large integrated application. These 
libraries enhance developer productivity by insulating them from much of the 
complexity associated with parallel programming model usage and 
system-specific memory concerns.

The software products provided by this project are three complementary and 
interoperable libraries:
\begin{enumerate}
\item {\bf RAJA:} Software abstractions that enable C++ developers to write performance portable (i.e., single-source) numerical kernels (loops). 
\item {\bf CHAI:} C++ ``managed array'' abstractions that enable transparent and automatic copying of application data to execution memory spaces at run time as needed based on RAJA execution contexts.
\item {\bf Umpire:} A portable memory resource management library that provides a unified high-level API for resource discovery, memory provisioning, allocation, access, operations, and introspection.
\end{enumerate}

Capabilities delivered by these software efforts are needed to manage the
diversity and uncertainty associated with current and future HPC architecture
design and software support. Moving forward, ECP applications and libraries 
need to achieve performance portability: without becoming bound to particular
(potentially-limiting) hardware or software technologies, by insulating 
numerical algorithms from platform-specific data and execution concerns, and 
without major disruption as new machine, programming models, and vendor
software become available.

These libraries in development in this project are currently used in 
production ASC applications at Lawrence Livermore National Laboratory 
(LLNL). They are also being used or being explored/adopted by several ECP 
application and library projects, including: LLNL ATDM application, GEOS (Subsurface), SW4 (EQSIM), MFEM (CEED co-design), and SUNDIALS.

The software projects are highly-leveraged with other efforts. Team members 
include: ASC and ATDM application developers, ASD tool developers, university 
collaborators, and vendors. This ECP ST project supports outreach to the ECP
community and collaboration with ECP efforts.

\paragraph{Key Challenges.}

The main technical challenge for this project is enabling production
applications to achieve performance portability in an environment of rapidly 
changing, disruptive HPC hardware architecture design. Typical large 
applications contain $O(10^5) - O(10^6)$ lines of code and $O(10K)$ loop 
kernels. The codes must run efficiently on platforms ranging from 
laptops to commodity clusters to large HPC platforms. The codes are 
long-lived and are used daily for decades, so they must be portable across 
machine generations. Also, the codes are under continual development, with a 
steady stream of new capabilities added throughout their lifetimes -- continual 
validation and verification is essential, which precludes substantial rewrites
from scratch. Lastly, the complex interplay of multiple physics packages 
and dozens of libraries makes it so that the data required for the full set of 
components needed for a given simulation may not fit into a single system
memory space. To advance scientific computing capabilities, applications 
must navigate these constraints while facing substantial hardware architecture 
disruption along the road toward Exascale computing platforms. 

While the software provided by this project has a substantial user base at
LLNL, achieving broader adoption in the ECP (projects without LLNL involvement, 
in particular) is another challenge. The software efforts are funded almost 
entirely by LLNL programs and the majority of their developers work on LLNL 
application projects. So resource limitations is a key issue.

\paragraph{Solution Strategy.}

The software libraries in this project focus on encapsulation and 
application-facing APIs to insulate users from the complexity and 
challenges associated with diverse forms of parallelism and heterogeneous 
memory systems. This approach allows users to exploit new capabilities 
with manageable rewriting of their applications.

RAJA provides various C++ abstractions for parallel loop execution. It
supports: various parallel programming model back-ends, such as OpenMP 
(CPU multithreading and target offload), CUDA, Intel Threading Building Blocks,
etc.; loop iteration space and data view constructs to reorder, 
aggregate, tile, and partition loop iterations; complex loop kernel 
transformations for optimization, such as reordering loop nests, fusing 
loops, etc. RAJA also supports portable atomic operations, parallel scans, 
and CPU and GPU shared memory. After loops have been converted to RAJA, 
developers can explore implementation alternatives via RAJA features without 
altering loop kernels at the application level.

CHAI provides C++ ``managed array'' abstractions that automatically copy 
data to execution memory spaces as needed at run time based on RAJA execution 
contexts. Access to array data in loop kernels looks the same as when using
traditional C-style arrays.

Umpire provides a portable API for managing complex memory resources by 
providing uniform access to other libraries and utilities that provide
system-specific capabilities. Umpire decouples resource allocation from 
specific memory spaces, allocators, and operations. The memory introspection 
functionality of Umpire enables applications and libraries to make memory 
usage decisions based on allocation properties (size, location, sharing 
between packages, etc.)

All three software libraries are open source and 
available on GitHub~\cite{RAJA-github, CHAI-github, Umpire-github}. There they 
provide regular software and documentation releases. Each project has 
dedicated email lists, issue tracking, test suites, and automated testing.

\paragraph{Recent Progress}

In FY18, CHAI and Umpire have been released as open source software projects
and they are now developed on GitHub Recent development has focused on 
user documentation and cleaner integration of these two libraries to give 
applications more flexible and easy access to their capabilities.

Many new features have been added to RAJA in FY18 to enable flexible
loop transformations for complex loop kernels via execution policies.
LLNL applications are assessing this new functionality now in a 
"pre-release" version; it will be generally available before the end of FY18.

The RAJA Performance Suite~\cite{RAJAPerf-github} was released and made 
available on Github in January 2018. The Suite is used to assess and track 
performance of RAJA across programming models and diverse loop 
kernels. It is also being used for compiler acceptance testing in the CORAL 
procurement and was prepared for use as a benchmark for the CORAL-2 procurement.

In 2018, the RAJA project expanded its visibility beyond DOE NNSA Labs. 
Recent presentations include a RAJA tutorial at the 2018 ECP Annual Meeting 
and an application use case study the 2018 NVIDIA GPU Tech Conference (GTC). 
Future tutorials are planned at 2018 ATPESC and GTC 2019. Also, a RAJA paper 
and $1/2$-day tutorial proposal were submitted to SC18.

\paragraph{Next Steps}

Our next efforts include:
\begin{enumerate}
\item {\bf Fill RAJA Gaps:} Not all features are available for all programming model back-ends; as models mature, such as OpenMP4.5, these gaps will be filled.
\item {\bf Expand RAJA User Guide and Tutorial:} Build example codes and user documentation for latest RAJA features and prepare for future tutorials (ATPESC 2018 and SC18).
\item {\bf Expand RAJA Performance Suite:} Include kernels that exercise more application use cases and RAJA features.
\item {\bf Focus RAJA Vendor Interaction:} Work with CORAL vendors to address issues as applications port to the Sierra platform at LLNL; establish early interactions with CORAL-2 vendors to ensure RAJA will be supported well on CORAL-2 systems.
\item {\bf CHAI-Umpire Integration:} Enable applications to customize CHAI array allocations; e.g., to use memory pools for temporaries.
\item {\bf Expand Umpire Capabilities:} Explore potential collaboration with relevant ECP efforts, such as SICM project.
\end{enumerate}
