\newcommand{\zfp}{\textsc{zfp}}

\subsubsection{\stid{4.11} ZFP: Compressed Floating-Point Arrays}

\paragraph{Overview} 

One of the primary challenges for Exascale computing is overcoming the
performance cost of data movement.  Through simulation, observation, and
experiments, far more data is being generated than can reasonably be stored
to disk and later analyzed without any form of data reduction.  Moreover,
with deepening memory hierarchies and dwindling per-core memory bandwidth
due to increasing parallelism, even on-node data motion between RAM and
registers makes for a significant performance bottleneck and primary source
of power consumption.

{\zfp} is a floating-point array primitive that mitigates this problem using
very high-speed, lossy (but optionally error-bounded) compression to
significantly reduce data volumes.  {\zfp} reduces I/O time and off-line
storage requirements by 1--2 orders of magnitude depending on accuracy
requirements, as dictated by user-set error tolerances.  Unique among data
compressors, {\zfp} also supports constant-time read/write random access to
individual array elements from compressed storage.  {\zfp}'s compressed arrays
can often replace conventional arrays in existing applications with minimal
code changes, allowing for instance the user to store tables of floating-point
data in compressed form that otherwise would not fit in memory, either using
a desired memory footprint or a prescribed level of accuracy.  When used in
numerical computations, {\zfp} arrays provide a fine-grained knob on precision
while achieving accuracy comparable to IEEE floating point at half the
storage, reducing both memory usage and bandwidth.

This project is extending {\zfp} to make it more readily usable in an Exascale
computing setting, by parallelizing it on both the CPU and GPU while ensuring
thread safety; by providing bindings for several programming languages (C,
C++, Fortran, Python); by adding new functionality, e.g., for unstructured
data and spatially adaptive compressed arrays; by hardening the software and
adopting best practices for software development; and by integrating {\zfp}
with a variety of ECP applications, I/O libraries, and visualization and data
analysis tools.


\paragraph{Key  Challenges}

There are several challenges to overcome on this project with respect
to implementing compressed floating-point arrays:
%
\begin{itemize}
\item \textbf{Data dependencies}.  Compression by its very nature removes
redundancies, often by deriving information from what has already been
(de)compressed and learned about the data.  Such data dependencies can
usually be resolved only by traversing the data in sequence, thus
complicating random access and parallelism.

\item \textbf{Random access}.  For inline compression, on-demand random
access to localized pieces of data is essential.  However, compression
usually represents large fixed-length records using variable-length
storage, which complicates random access and indexing.

\item \textbf{Parallelism}.  Manycore architectures allow for massively
concurrent execution over millions or billions of array elements.
Yet compression is usually a process of reducing such multidimensional
arrays to a single-dimensional
sequence of bits, which requires considerable coordination among parallel
threads of execution.

\item \textbf{Unstructured data}.  Unstructured data, such as independent
particles and arbitrarily connected nodes in a mesh, has no natural
ordering, repeated structure, or regular geometry that can be exploited
for compression.

\item \textbf{Performance}.  For inline compression to be useful, both
compression and decompression have to be extremely fast (simple), yet
effective enough to warrant compression.  Moreover, the complexities of
compression must be hidden from the user to promote adoption, while allowing
sufficient flexibility to support essentially arbitrary data access patterns.
\end{itemize}
%
These challenges often suggest conflicting solutions and are further
complicated by the extreme demands of Exascale computing applications.

\paragraph{Solution Strategy}


{\zfp} is unique in supporting read and write random access to
multidimensional data, and was designed from the outset to address
some of the above challenges.  The following strategies are employed on
this project to overcome the remaining challenges:
%
\begin{itemize}
\item \textbf{Partitioning}.  $d$-dimensional arrays are partitioned
into small, independent blocks of $4^d$ scalars each.  This enables both
fine-grained random access and a large degree of data parallelism.

\item \textbf{Fixed-size storage}.  Instead of storing fixed-precision
values using variable-size storage, {\zfp} uses fixed-size storage to
represent values at the greatest precision afforded by a limited
bit budget.

\item \textbf{Adaptive storage}.  For applications that demand error
tolerances, this project is developing adaptive representations that
allocate bits to where they are most needed, which involves efficient
management of variable-length records that might expand and shrink in
size over time.

\item \textbf{Parallelism}.  OpenMP and CUDA implementations of {\zfp}
are being developed that primarily exploit fine-grained data parallelism,
but which also take advantage of task parallelism.

\item \textbf{Preconditioning}.  The irregularity and unpredictability
of unstructured data is improved using \emph{preconditioners} that
``massage'' the data to make it more amenable to compression by {\zfp}.
Strategies include sorting, binning, structure inference, transposition,
pre-transforms like wavelets, etc.

\item \textbf{Abstraction}.  Concrete details about compression, caching,
parallelism, thread safety, etc., are abstracted away from the user by
providing high-level primitives that make {\zfp} arrays appear like
uncompressed arrays, in part via C++ operator overloading.  We are
designing classes and concepts commonly available for uncompressed arrays,
such as proxy references and pointers into compressed storage that act
like their uncompressed counterparts; views into and slices of arrays;
and iterators compatible with STL algorithms.  Such primitives make it
easier to write generic code for which {\zfp} arrays may easily be
substituted for uncompressed arrays.
\end{itemize}

\paragraph{Recent Progress}

This project has made progress on several fronts over the past year to make
the {\zfp} software~\cite{zfp-code} more Exascale ready and capable.
Improved software development practices have been adopted, such as continuous
integration, unit testing, extensive documentation~\cite{zfp-docs}, and
portable build processes based on CMake and SPACK.  A novel C equivalent of
name spaces has been developed to allow linking to multiple versions of {\zfp}
in the same library or executable to enable access to persistent files written
using an evolving {\zfp} CODEC.
{\zfp} compressed arrays can now be accessed using primitives with
semantics equivalent to those commonly available for uncompressed scalar
types and containers, such as proxy references and pointers, iterators,
and flat and nested views and slices.
The work on views has also laid the ground for enabling
thread-safe access to {\zfp} compressed arrays, e.g., by enabling
shared, read-only access among threads, in addition to partitioning into
independent sub-arrays for read-write multithreaded access.  {\zfp} has
further been parallelized to support both OpenMP and CUDA execution,
yielding throughput as high as 20 GB/s using 32 threads.

Finally, significant effort has been made to deploy {\zfp} to ECP tools
and applications.  For instance, {\zfp} compression is available in the
ADIOS and HDF5 I/O libraries and has been specialized for the Cinema
database format for in-situ visualization.  A compressed
format is being developed for the CEED high-order finite-element co-design
center.  Compression studies have been performed for the QMCPACK, ExaSMR,
and ExaSky ECP applications, in which {\zfp} compressed arrays are being
considered.

The results of these R\&D efforts have been documented through
publications~\cite{zfp-isc2017,zfp-jsm2017}, and significant efforts have
been made to reach out to customers and the HPC community at large through
one-on-one interactions and tutorials, both at ECP meetings and
conferences~\cite{zfp-isc2017-tut,zfp-sc2017-tut,zfp-ep2018-tut}.

\noindent
\begin{minipage}[t]{3.75in}
\paragraph{Next Steps}

Efforts are underway to provide C, Python, and Fortran bindings for
{\zfp} arrays to facilitate integration with applications not written in
C++.  Additionally, new capabilities are being added to the main compression
CODEC to support 4D and higher-dimensional arrays; missing/undefined array
values and special values like NaNs and infinities; and lossless compression.
Our CUDA implementation will serve as the basis for a new GPU-based
compressed array primitive for VTK-m.  Longer-term efforts include
strategies for coping with unstructured data and spatially adaptive
compressed arrays.
\end{minipage}%
\hspace*{0.125in}%
\begin{minipage}[t]{2.625in}
\vspace{0pt}%
\vspace{-3ex}%
\includegraphics[width=\columnwidth]{projects/2.3.4-DataViz/2.3.4.11-ZFP/ZFP}%
\vspace{-2ex}%
\captionof{figure}{240:1 {\zfp} compressed density field.}%
\label{fig:zfp-result}%
\end{minipage}
