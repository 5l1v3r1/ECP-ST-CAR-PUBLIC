\subsection{\ecosystem}

\textbf{End State:} A production-ready software stack delivered to our facilities, vendor partners, and the open source HPC community.

\subsubsection{Scope and Requirements}
The focus of this effort is on the ``last mile'' delivery of software that is intended to be supported by DOE Facilities and/or vendor offerings. The scope of this effort breaks down into the following key areas:
\begin{itemize}
	\item Oversight of the ST SDKs (Software Development Kits) developed in all five ST L3 areas, with a goal of ensuring the SDKs are deployed as production-quality products at the Facilities, and available to the broader open-source HPC community through coordinated releases
	\item Development of testing infrastructure (e.g., Continuous Integration) for use by ECP teams at the Facilities
	\item Hardening and broad ST and facility adoption of Spack for easy build of software on all target platforms
	\item Development and hardening of new methods for software deployment through the use of container technology
	\item Informal partnerships with the Linux Foundation's OpenHPC project for potential broader deployment of ST technologies in the OpenHPC ecosystem
	\item Co-design of ST solutions with (primarily ATDM) application teams, particularly in the area of programming models, abstractions for performance portability, and optimized use on Exascale systems
	\item System software that is typically provided by the vendors on a platform, or tightly integrated with vendor solutions – including resource managers, low-level runtimes, power management, and support for hierarchical memory at the Operating System (OS) level
	\item Development of Flang through a subcontract with NVIDIA – a first-of-its-kind open source Fortran compiler built on the LLVM toolchain
	\item Research in resilience to understand the impacts of faults on applications, software, and systems
\end{itemize}
A major goal of ST is to ensure that applications can trust that ST products will be available on DOE Exascale systems in a production-quality state, which implies robust testing, documentation, and a clear line of support for each product. This will largely be an integration effort building on both the SDKs project elements defined in each ST L3 area, and tight collaboration and coordination with the Hardware Integration L3 area for Deployment of Software on Facilities (WBS 2.4.4). We will work to develop foundational infrastructure for technologies such as continuous integration and containers in tight collaboration with our DOE facility partners. The ultimate goal is ensuring that the ECP software stack is robustly supported, as well as finding a reach into the broader HPC open-source community – both of which provide the basis for long-term sustainment required by applications, software, Facilities, and vendors who rely upon these products.

All three of the ATDM efforts in this area have a focus on integration of technologies into their new ATDM applications being developed “from scratch” under AD National Security Applications. ATDM applications are a high-risk, high-reward effort under tight timelines for delivery to the NNSA mission, and thus must focus on integration with key ST technologies being developed at those labs from the beginning. 

System software in the form of operating systems capabilities and low-level runtimes has historically been built upon a node-centric viewpoint with a global view of the system tied together in a patchwork of add-on tools and resource managers. In order to support higher-level software development, low-level software layers must be provided to address hierarchical and non-uniform memory management, dynamic power management, lightweight threading and process management, low-level distributed data movement (i.e., messaging), I/O forwarding, and resilience and integrity issues. In addition, support for sophisticated resource scheduling and management, including storage, must account for the ability to accomplish increasingly complex workflows (e.g., ensembles, multi-physics, scale bridging, and uncertainly quantification). 

The overarching goal of the resilience and integrity (RI) effort is to keep the application workload running to an acceptably correct solution in a timely and efficient manner on future systems, even in the presence of increasing failures, challenges in I/O scalability for checkpoint/restart, and silent (undetected) errors.

\subsubsection{Assumptions and Feasibility}
Success in this effort will require a coordinated effort across the entire hardware and software stack – in particular with HI 2.4.4 (Delivery of Software to Facilities) and in some cases, our vendor partners. Recent restructuring of the ECP to formalize this cooperation is a critical first step in enabling our goals, and this area will drive toward ensuring those partnerships can flourish for mutual gain.

Given the project timelines and requirements of production systems at our Facilities, we do not envision a wholly new system software stack as a feasible solution. We do however recognize that in many cases the features of today's HPC operating system environments will very likely need to either be evolved or extended to meet the mission goals. This will require first, proof-of-concept on existing pre-Exascale hardware, and ultimately – adoption of technologies by system vendors where required, and by other application and software teams where user-level (i.e., non-kernel) solutions are developed. 

\subsubsection{Objectives}
This area will focus on all aspects of integration of the ECP software stack, with a focus on putting the infrastructure in place (in partnership with HI and the SDKs) for production-quality software delivery through technologies such as continuous integration and containers. Likewise, we will aim to influence the deployment of operating system, low-level runtimes, and perhaps containers typically deployed by our vendor partners. Finally, our ATDM projects will focus on delivery and integration of novel software technologies into next-generation applications under development in AD National Security Applications – with a goal of demonstrating and hardening those technologies for possible use in other applications.

Additional goals include providing infrastructure and higher-level tools that address the requirements and extensions for better resource allocation and job scheduling capabilities. These changes will address the necessary aspects of system architectures, including storage resources, and the support for increasingly complex workflows that are projected to occur within the Exascale environment. 

The Flang effort is being developed by NVIDIA's PGI compiler team based on the robust and widely used PGF compiler. Flang was released on GitHub as an open source project in 2017, and is making solid progress toward performance and portability goals. Our objective is to have Flang supported at the DOE Facilities for use by ECP application teams, as well as taken up by vendors (Arm being an early adopter) as a first-class Fortran solution

The objective of resilience efforts is that applications will run successfully and efficiently to timely completion in the presence of any faults experienced on the system. Application developers will have the necessary programming tools, libraries, and system support for incorporating resilience into their code. This will include access to nonvolatile memory, fault tolerant libraries, and scientific libraries that are resilient to soft errors and support application developers to implement their own resilient algorithms.

\subsubsection{Plan}
Initial efforts will be aimed at developing and deploying a continuous integration system at each of the DOE Facilities based on the results of a working group established in 2017 that defined the key gaps missing in current prototype CI solutions. In parallel with that effort, we will work closely with the five SDK projects in developing a long-term plan for software deployment. We will also begin efforts to evaluate existing container technologies (e.g., Bee, Argo, Singularity, others) built upon the widely-adopted Docker technology base, and build on facility collaborations established for CI deployment to develop one or more solutions for container deployment that meet the unique HPC requirements for performance and security. As Flang becomes competitive in features and performance with other Fortran compilers, we will work with AD projects on defining the scope of work for NVIDIA/PGI, and with the Facilities on deployment of recent Flang releases for broad community testing and use.

Our plan is to hire an ECP Release Engineer who can work closely with the individual SDK projects in each L3 area to develop common practices and delivery mechanisms. This could include a pathway for SDKs into OpenHPC, as well as well-publicized incremental releases of SDKs.

\subsubsection{Risks and Mitigations Strategies}
\begin{itemize}
	\item Vendors unwilling to adopt aspects of the Argo environment that require kernel-level support.
	\item Inability to staff the release engineer position with a qualified candidate (someone with DevOps expertise who also understands the HPC environment).
	\item Delays in deploying a common CI infrastructure lead to subsequent delays in an integrated software release.
	\item Multiple container technologies in flight will make it hard to come to agreement on a “common” looking solution. Singularity isn't funded by ECP. BEE and Argo are the only ECP funded items, and it is unclear if they are the right final solution.
	\item Resilience work is a tiny fraction of effort. May need to consider a software co-design center around this topic that would marry efforts between apps, ST, and vendors.
	\item ATDM efforts may continue to be inward-facing and not suitable for longer-term broad adoption if/when technologies are successfully borne out in practice.
	\item OpenHPC partnership is ill-defined, and unfunded.
	\item Sustainability of ECP ST capabilities after ECP has ended.
\end{itemize}
